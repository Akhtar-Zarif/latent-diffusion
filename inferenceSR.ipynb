{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/CompVis/latent-diffusion.git\n",
    "# !git clone https://github.com/CompVis/taming-transformers\n",
    "# !pip install -e ./taming-transformers\n",
    "# !pip install ipywidgets omegaconf>=2.0.0 pytorch-lightning>=1.0.8 torch-fidelity einops\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\".\")\n",
    "# sys.path.append('./taming-transformers')\n",
    "# from taming.models import vqgan # checking correct import from taming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3841664530bf4542926bf0d58cbb99aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Task:', options=('superresolution',), value='superresolution')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %cd latent-diffusion\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "mode = widgets.Select(options=['superresolution'],\n",
    "    value='superresolution', description='Task:')\n",
    "display(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3cd895bb5649f8be0ea1907f3d00a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='SR resolutions:', index=1, options=('64-256', '32-64'), value='32-64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resolution = widgets.Select(options=['64-256', '32-64'],\n",
    "    value='32-64', description='SR resolutions:')\n",
    "display(resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64-256 selected\n"
     ]
    }
   ],
   "source": [
    "# Define variables\n",
    "\n",
    "## LDM 64->256\n",
    "if resolution.value == \"64-256\":\n",
    "    print(\"64-256 selected\")\n",
    "    path_conf = \".\\\\models\\\\trained_model_config\\\\ffhq256_sr.yaml\"\n",
    "    path_ckpt = \".\\\\trained_models\\\\epoch=000052.ckpt\"\n",
    "    up_f = 4\n",
    "## LDM 32->64\n",
    "elif resolution.value == \"32-64\":\n",
    "    print(\"32-64 selected\")\n",
    "    path_conf = \".\\\\models\\\\trained_model_config\\\\ffhq32-64_sr.yaml\"\n",
    "    path_ckpt = \".\\\\trained_models\\\\epoch=000014.ckpt\"\n",
    "    up_f = 2\n",
    "# path_conf = \".\\\\models\\\\ldm\\\\ffhq256\\\\ffhq256_sr.yaml\"\n",
    "# path_ckpt = \".\\\\trained_models\\\\epoch=000052.ckpt\"\n",
    "\n",
    "# path_conf = \".\\\\models\\\\ldm\\\\ffhq256\\\\ffhq32-64_sr.yaml\"\n",
    "# path_ckpt = \".\\\\trained_models\\\\epoch=000014.ckpt\"\n",
    "# uploaded_img = \"\" # 给一张照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.path.isfile(path_ckpt)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from .\\trained_models\\epoch=000052.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 113.62 M params.\n",
      "Keeping EMAs of 308.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 3, 64, 64) = 12288 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Restored from ./models/first_stage_models/vq-f4/model.ckpt with 0 missing and 55 unexpected keys\n"
     ]
    }
   ],
   "source": [
    "from notebook_helpers import get_local_model\n",
    "model = get_local_model(path_conf, path_ckpt) # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from notebook_helpers import get_custom_cond\n",
    "\n",
    "# get_custom_cond(mode.value, uploaded_img=uploaded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f153e031f2054412a747295f450a363e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Select conditioning:', options=('face256_1.png', 'face32_1.png', 'face32_2.png', 'fa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_helpers import get_cond_options, get_cond\n",
    "dir, options = get_cond_options(mode.value)\n",
    "cond_choice = widgets.RadioButtons(\n",
    "        options=options,\n",
    "        description='Select conditioning:',\n",
    "        disabled=False\n",
    "    )\n",
    "display(cond_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyeheyhey\n",
      "original c shape: torch.Size([1, 3, 64, 64])\n",
      "heyeheyhey\n",
      "torch.Size([1, 64, 64, 3]) torch.Size([1, 256, 256, 3])\n",
      "reducing Kernel\n",
      "Plotting: Switched to EMA weights\n",
      "Sampling with eta = 1.0; steps: 200\n",
      "Data shape for DDIM sampling is (1, 3, 64, 64), eta 1.0\n",
      "Running DDIM Sampling with 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler:   0%|          | 0/200 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting: Restored training weights\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and non-zero dimensions for input, but got: [1, 16384, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m custom_steps \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[0;32m      4\u001b[0m cond_choice_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mdir\u001b[39m, cond_choice\u001b[39m.\u001b[39mvalue)\n\u001b[1;32m----> 5\u001b[0m logs \u001b[39m=\u001b[39m run(model[\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m], cond_choice_path, mode\u001b[39m.\u001b[39;49mvalue, custom_steps, up_f)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\notebook_helpers.py:188\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(model, selected_path, task, custom_steps, up_f, resize_enabled, classifier_ckpt, global_step)\u001b[0m\n\u001b[0;32m    185\u001b[0m         x_T \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, custom_shape[\u001b[39m1\u001b[39m], custom_shape[\u001b[39m2\u001b[39m], custom_shape[\u001b[39m3\u001b[39m])\u001b[39m.\u001b[39mto(model\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    186\u001b[0m         x_T \u001b[39m=\u001b[39m repeat(x_T, \u001b[39m'\u001b[39m\u001b[39m1 c h w -> b c h w\u001b[39m\u001b[39m'\u001b[39m, b\u001b[39m=\u001b[39mcustom_shape[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 188\u001b[0m     logs \u001b[39m=\u001b[39m make_convolutional_sample(example, model,\n\u001b[0;32m    189\u001b[0m                                      mode\u001b[39m=\u001b[39;49mmode, custom_steps\u001b[39m=\u001b[39;49mcustom_steps,\n\u001b[0;32m    190\u001b[0m                                      eta\u001b[39m=\u001b[39;49meta, swap_mode\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m , masked\u001b[39m=\u001b[39;49mmasked,\n\u001b[0;32m    191\u001b[0m                                      invert_mask\u001b[39m=\u001b[39;49minvert_mask, quantize_x0\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    192\u001b[0m                                      custom_schedule\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, decode_interval\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m    193\u001b[0m                                      resize_enabled\u001b[39m=\u001b[39;49mresize_enabled, custom_shape\u001b[39m=\u001b[39;49mcustom_shape,\n\u001b[0;32m    194\u001b[0m                                      temperature\u001b[39m=\u001b[39;49mtemperature, noise_dropout\u001b[39m=\u001b[39;49m\u001b[39m0.\u001b[39;49m,\n\u001b[0;32m    195\u001b[0m                                      corrector\u001b[39m=\u001b[39;49mguider, corrector_kwargs\u001b[39m=\u001b[39;49mckwargs, x_T\u001b[39m=\u001b[39;49mx_T, save_intermediate_vid\u001b[39m=\u001b[39;49msave_intermediate_vid,\n\u001b[0;32m    196\u001b[0m                                      make_progrow\u001b[39m=\u001b[39;49mmake_progrow,ddim_use_x0_pred\u001b[39m=\u001b[39;49mddim_use_x0_pred\n\u001b[0;32m    197\u001b[0m                                      )\n\u001b[0;32m    198\u001b[0m \u001b[39mreturn\u001b[39;00m logs\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\notebook_helpers.py:261\u001b[0m, in \u001b[0;36mmake_convolutional_sample\u001b[1;34m(batch, model, mode, custom_steps, eta, swap_mode, masked, invert_mask, quantize_x0, custom_schedule, decode_interval, resize_enabled, custom_shape, temperature, noise_dropout, corrector, corrector_kwargs, x_T, save_intermediate_vid, make_progrow, ddim_use_x0_pred)\u001b[0m\n\u001b[0;32m    258\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    259\u001b[0m img_cb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m sample, intermediates \u001b[39m=\u001b[39m convsample_ddim(model, c, steps\u001b[39m=\u001b[39;49mcustom_steps, shape\u001b[39m=\u001b[39;49mz\u001b[39m.\u001b[39;49mshape,\n\u001b[0;32m    262\u001b[0m                                         eta\u001b[39m=\u001b[39;49meta,\n\u001b[0;32m    263\u001b[0m                                         quantize_x0\u001b[39m=\u001b[39;49mquantize_x0, img_callback\u001b[39m=\u001b[39;49mimg_cb, mask\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, x0\u001b[39m=\u001b[39;49mz0,\n\u001b[0;32m    264\u001b[0m                                         temperature\u001b[39m=\u001b[39;49mtemperature, noise_dropout\u001b[39m=\u001b[39;49mnoise_dropout,\n\u001b[0;32m    265\u001b[0m                                         score_corrector\u001b[39m=\u001b[39;49mcorrector, corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs,\n\u001b[0;32m    266\u001b[0m                                         x_T\u001b[39m=\u001b[39;49mx_T, log_every_t\u001b[39m=\u001b[39;49mlog_every_t)\n\u001b[0;32m    267\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    269\u001b[0m \u001b[39mif\u001b[39;00m ddim_use_x0_pred:\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\notebook_helpers.py:212\u001b[0m, in \u001b[0;36mconvsample_ddim\u001b[1;34m(model, cond, steps, shape, eta, callback, normals_sequence, mask, x0, quantize_x0, img_callback, temperature, noise_dropout, score_corrector, corrector_kwargs, x_T, log_every_t)\u001b[0m\n\u001b[0;32m    210\u001b[0m shape \u001b[39m=\u001b[39m shape[\u001b[39m1\u001b[39m:]  \u001b[39m# cut batch dim\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSampling with eta = \u001b[39m\u001b[39m{\u001b[39;00meta\u001b[39m}\u001b[39;00m\u001b[39m; steps: \u001b[39m\u001b[39m{\u001b[39;00msteps\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 212\u001b[0m samples, intermediates \u001b[39m=\u001b[39m ddim\u001b[39m.\u001b[39;49msample(steps, batch_size\u001b[39m=\u001b[39;49mbs, shape\u001b[39m=\u001b[39;49mshape, conditioning\u001b[39m=\u001b[39;49mcond, callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    213\u001b[0m                                      normals_sequence\u001b[39m=\u001b[39;49mnormals_sequence, quantize_x0\u001b[39m=\u001b[39;49mquantize_x0, eta\u001b[39m=\u001b[39;49meta,\n\u001b[0;32m    214\u001b[0m                                      mask\u001b[39m=\u001b[39;49mmask, x0\u001b[39m=\u001b[39;49mx0, temperature\u001b[39m=\u001b[39;49mtemperature, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    215\u001b[0m                                      score_corrector\u001b[39m=\u001b[39;49mscore_corrector,\n\u001b[0;32m    216\u001b[0m                                      corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs, x_T\u001b[39m=\u001b[39;49mx_T)\n\u001b[0;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m samples, intermediates\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\ldm\\models\\diffusion\\ddim.py:95\u001b[0m, in \u001b[0;36mDDIMSampler.sample\u001b[1;34m(self, S, batch_size, shape, conditioning, callback, normals_sequence, img_callback, quantize_x0, eta, mask, x0, temperature, noise_dropout, score_corrector, corrector_kwargs, verbose, x_T, log_every_t, unconditional_guidance_scale, unconditional_conditioning, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m size \u001b[39m=\u001b[39m (batch_size, C, H, W)\n\u001b[0;32m     93\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mData shape for DDIM sampling is \u001b[39m\u001b[39m{\u001b[39;00msize\u001b[39m}\u001b[39;00m\u001b[39m, eta \u001b[39m\u001b[39m{\u001b[39;00meta\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 95\u001b[0m samples, intermediates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mddim_sampling(conditioning, size,\n\u001b[0;32m     96\u001b[0m                                             callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m     97\u001b[0m                                             img_callback\u001b[39m=\u001b[39;49mimg_callback,\n\u001b[0;32m     98\u001b[0m                                             quantize_denoised\u001b[39m=\u001b[39;49mquantize_x0,\n\u001b[0;32m     99\u001b[0m                                             mask\u001b[39m=\u001b[39;49mmask, x0\u001b[39m=\u001b[39;49mx0,\n\u001b[0;32m    100\u001b[0m                                             ddim_use_original_steps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    101\u001b[0m                                             noise_dropout\u001b[39m=\u001b[39;49mnoise_dropout,\n\u001b[0;32m    102\u001b[0m                                             temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m    103\u001b[0m                                             score_corrector\u001b[39m=\u001b[39;49mscore_corrector,\n\u001b[0;32m    104\u001b[0m                                             corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs,\n\u001b[0;32m    105\u001b[0m                                             x_T\u001b[39m=\u001b[39;49mx_T,\n\u001b[0;32m    106\u001b[0m                                             log_every_t\u001b[39m=\u001b[39;49mlog_every_t,\n\u001b[0;32m    107\u001b[0m                                             unconditional_guidance_scale\u001b[39m=\u001b[39;49munconditional_guidance_scale,\n\u001b[0;32m    108\u001b[0m                                             unconditional_conditioning\u001b[39m=\u001b[39;49munconditional_conditioning,\n\u001b[0;32m    109\u001b[0m                                             )\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m samples, intermediates\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\ldm\\models\\diffusion\\ddim.py:148\u001b[0m, in \u001b[0;36mDDIMSampler.ddim_sampling\u001b[1;34m(self, cond, shape, x_T, ddim_use_original_steps, callback, timesteps, quantize_denoised, mask, x0, img_callback, log_every_t, temperature, noise_dropout, score_corrector, corrector_kwargs, unconditional_guidance_scale, unconditional_conditioning)\u001b[0m\n\u001b[0;32m    145\u001b[0m     img_orig \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mq_sample(x0, ts)  \u001b[39m# TODO: deterministic forward pass?\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     img \u001b[39m=\u001b[39m img_orig \u001b[39m*\u001b[39m mask \u001b[39m+\u001b[39m (\u001b[39m1.\u001b[39m \u001b[39m-\u001b[39m mask) \u001b[39m*\u001b[39m img\n\u001b[1;32m--> 148\u001b[0m outs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mp_sample_ddim(img, cond, ts, index\u001b[39m=\u001b[39;49mindex, use_original_steps\u001b[39m=\u001b[39;49mddim_use_original_steps,\n\u001b[0;32m    149\u001b[0m                           quantize_denoised\u001b[39m=\u001b[39;49mquantize_denoised, temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m    150\u001b[0m                           noise_dropout\u001b[39m=\u001b[39;49mnoise_dropout, score_corrector\u001b[39m=\u001b[39;49mscore_corrector,\n\u001b[0;32m    151\u001b[0m                           corrector_kwargs\u001b[39m=\u001b[39;49mcorrector_kwargs,\n\u001b[0;32m    152\u001b[0m                           unconditional_guidance_scale\u001b[39m=\u001b[39;49munconditional_guidance_scale,\n\u001b[0;32m    153\u001b[0m                           unconditional_conditioning\u001b[39m=\u001b[39;49munconditional_conditioning)\n\u001b[0;32m    154\u001b[0m img, pred_x0 \u001b[39m=\u001b[39m outs\n\u001b[0;32m    155\u001b[0m \u001b[39mif\u001b[39;00m callback: callback(i)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\ldm\\models\\diffusion\\ddim.py:171\u001b[0m, in \u001b[0;36mDDIMSampler.p_sample_ddim\u001b[1;34m(self, x, c, t, index, repeat_noise, use_original_steps, quantize_denoised, temperature, noise_dropout, score_corrector, corrector_kwargs, unconditional_guidance_scale, unconditional_conditioning)\u001b[0m\n\u001b[0;32m    168\u001b[0m b, \u001b[39m*\u001b[39m_, device \u001b[39m=\u001b[39m \u001b[39m*\u001b[39mx\u001b[39m.\u001b[39mshape, x\u001b[39m.\u001b[39mdevice\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m unconditional_conditioning \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m unconditional_guidance_scale \u001b[39m==\u001b[39m \u001b[39m1.\u001b[39m:\n\u001b[1;32m--> 171\u001b[0m     e_t \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mapply_model(x, t, c)\n\u001b[0;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     x_in \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x] \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\ldm\\models\\diffusion\\ddpm.py:937\u001b[0m, in \u001b[0;36mLatentDiffusion.apply_model\u001b[1;34m(self, x_noisy, t, cond, return_ids)\u001b[0m\n\u001b[0;32m    933\u001b[0m stride \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_input_params[\u001b[39m\"\u001b[39m\u001b[39mstride\u001b[39m\u001b[39m\"\u001b[39m]  \u001b[39m# eg. (64, 64)\u001b[39;00m\n\u001b[0;32m    935\u001b[0m h, w \u001b[39m=\u001b[39m x_noisy\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m--> 937\u001b[0m fold, unfold, normalization, weighting \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_fold_unfold(x_noisy, ks, stride)\n\u001b[0;32m    939\u001b[0m z \u001b[39m=\u001b[39m unfold(x_noisy)  \u001b[39m# (bn, nc * prod(**ks), L)\u001b[39;00m\n\u001b[0;32m    940\u001b[0m \u001b[39m# Reshape to img shape\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cj020\\Desktop\\Diffusion Research\\latent-diffusion\\ldm\\models\\diffusion\\ddpm.py:621\u001b[0m, in \u001b[0;36mLatentDiffusion.get_fold_unfold\u001b[1;34m(self, x, kernel_size, stride, uf, df)\u001b[0m\n\u001b[0;32m    618\u001b[0m     fold \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mFold(output_size\u001b[39m=\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfold_params)\n\u001b[0;32m    620\u001b[0m     weighting \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_weighting(kernel_size[\u001b[39m0\u001b[39m], kernel_size[\u001b[39m1\u001b[39m], Ly, Lx, x\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mto(x\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m--> 621\u001b[0m     normalization \u001b[39m=\u001b[39m fold(weighting)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, h, w)  \u001b[39m# normalizes the overlap\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     weighting \u001b[39m=\u001b[39m weighting\u001b[39m.\u001b[39mview((\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, kernel_size[\u001b[39m0\u001b[39m], kernel_size[\u001b[39m1\u001b[39m], Ly \u001b[39m*\u001b[39m Lx))\n\u001b[0;32m    624\u001b[0m \u001b[39melif\u001b[39;00m uf \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m df \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\nn\\modules\\fold.py:146\u001b[0m, in \u001b[0;36mFold.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 146\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mfold(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation,\n\u001b[0;32m    147\u001b[0m                   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride)\n",
      "File \u001b[1;32mc:\\Users\\cj020\\anaconda3\\envs\\ldm\\lib\\site-packages\\torch\\nn\\functional.py:4691\u001b[0m, in \u001b[0;36mfold\u001b[1;34m(input, output_size, kernel_size, dilation, padding, stride)\u001b[0m\n\u001b[0;32m   4687\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39minput\u001b[39m):\n\u001b[0;32m   4688\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   4689\u001b[0m         fold, (\u001b[39minput\u001b[39m,), \u001b[39minput\u001b[39m, output_size, kernel_size, dilation\u001b[39m=\u001b[39mdilation, padding\u001b[39m=\u001b[39mpadding, stride\u001b[39m=\u001b[39mstride\n\u001b[0;32m   4690\u001b[0m     )\n\u001b[1;32m-> 4691\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcol2im(\n\u001b[0;32m   4692\u001b[0m     \u001b[39minput\u001b[39;49m, _pair(output_size), _pair(kernel_size), _pair(dilation), _pair(padding), _pair(stride)\n\u001b[0;32m   4693\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 2D or 3D (batch mode) tensor for input with possibly 0 batch size and non-zero dimensions for input, but got: [1, 16384, 0]"
     ]
    }
   ],
   "source": [
    "from notebook_helpers import run\n",
    "import os\n",
    "custom_steps = 200\n",
    "cond_choice_path = os.path.join(dir, cond_choice.value)\n",
    "logs = run(model[\"model\"], cond_choice_path, mode.value, custom_steps, up_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import IPython.display as d\n",
    "from PIL import Image\n",
    "\n",
    "sample = logs[\"sample\"]\n",
    "sample = sample.detach().cpu()\n",
    "sample = torch.clamp(sample, -1., 1.)\n",
    "sample = (sample + 1.) / 2. * 255\n",
    "sample = sample.numpy().astype(np.uint8)\n",
    "sample = np.transpose(sample, (0, 2, 3, 1))\n",
    "print(sample.shape)\n",
    "a = Image.fromarray(sample[0])\n",
    "display(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b11eaf0e94fc111c724b4ee42f36a114f13a982891d5c8efe533c6716daa5c0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
